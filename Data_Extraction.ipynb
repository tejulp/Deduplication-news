{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7192e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text\n",
    "import re\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from dateutil import parser\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e4b04",
   "metadata": {},
   "source": [
    "News Source #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.business-standard.com/latest-news'\n",
    "content = requests.get(URL)\n",
    "soup = BeautifulSoup(content.text, 'html.parser')\n",
    "headline = soup.find_all('a', attrs={'target': \"_blank\", 'href': True})\n",
    "headline_str = [headline[i].get_text() for i in range(len(headline))]\n",
    "\n",
    "headline_news = []\n",
    "list_true = []\n",
    "\n",
    "for i in range(len(headline_str)):\n",
    "    if(headline_str[i] != \"\"):\n",
    "        if (headline_str[i][0]).isdigit():\n",
    "            headline_news.append(headline_str[i])\n",
    "            list_true.append(i)\n",
    "            \n",
    "headline_abtract_links_raw = [str(anchor['href']) for anchor in headline]\n",
    "headline_abtract_links = ['https://www.business-standard.com'+headline_abtract_links_raw[i] for i in list_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453efcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BS_df = pd.DataFrame(list(zip(headline_news, headline_abtract_links)), columns =['Headline', 'Content Links']) \n",
    "BS_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e27f2",
   "metadata": {},
   "source": [
    "News Source #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.thehindubusinessline.com/latest-news/'\n",
    "content = requests.get(URL)\n",
    "soup = BeautifulSoup(content.text, 'html.parser')\n",
    "for ultag in soup.find_all('ul', {'class': 'latest-news'}):\n",
    "    headline = ultag.find_all('a', attrs={'href': True})\n",
    "headline_str = [headline[i].get_text() for i in range(len(headline))]\n",
    "headline_abtract_links_raw = [str(anchor['href']) for anchor in headline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a9f7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BL_df = pd.DataFrame(list(zip(headline_news, headline_abtract_links_raw)), columns =['Headline', 'Content Links']) \n",
    "BL_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533506be",
   "metadata": {},
   "source": [
    "News Source #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad39fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.livemint.com/latest-news'\n",
    "content = requests.get(URL)\n",
    "soup = BeautifulSoup(content.text, 'html.parser')\n",
    "for divtag in soup.find_all('div', attrs={'id': 'mylistView', 'class': 'listView'}):\n",
    "    headline = divtag.find_all('a', {'href': True})\n",
    "headline_str = [headline[i].get_text() for i in range(len(headline))]\n",
    "\n",
    "headline_news = []\n",
    "list_true = []\n",
    "\n",
    "for i in range(len(headline_str)):\n",
    "    if(headline_str[i] != \" \"):\n",
    "        headline_news.append(headline_str[i])\n",
    "        list_true.append(i)\n",
    "headline_abtract_links_raw = [str(anchor['href']) for anchor in headline]\n",
    "headline_abtract_links = [\"https://www.livemint.com\"+headline_abtract_links_raw[i] for i in list_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8b1b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Mint_df = pd.DataFrame(list(zip(headline_news, headline_abtract_links)), columns =['Headline', 'Content Links']) \n",
    "Mint_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5b8e0",
   "metadata": {},
   "source": [
    "Combine all data into 1 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc9ac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.concat([BS_df, BL_df, Mint_df], axis=0).reset_index(drop=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"/Users/tejulpandit/Desktop/Tejul/Code-Deduplication/News_Data_Extraction.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
